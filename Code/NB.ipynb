{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n4b2OzZXHtb_"
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "\n",
    "# Load DataSets\n",
    "train_df_one = pd.read_csv(\"/content/drive/MyDrive/Sentiment_Detection/SemEval-2017-Task-4-A-B-C-using-BERT-main/SemEval-2017-Task-4-A-B-C-using-BERT-main/data/twitter-2013train-A.txt\", delimiter='\\t', header=None, names=['id', 'label', 'tweet'])\n",
    "train_df_two = pd.read_csv(\"/content/drive/MyDrive/Sentiment_Detection/SemEval-2017-Task-4-A-B-C-using-BERT-main/SemEval-2017-Task-4-A-B-C-using-BERT-main/data/twitter-2016train-A.txt\", delimiter='\\t', header=None, names=['id', 'label', 'tweet'])\n",
    "train_df_three = pd.read_csv(\"/content/drive/MyDrive/Sentiment_Detection/SemEval-2017-Task-4-A-B-C-using-BERT-main/SemEval-2017-Task-4-A-B-C-using-BERT-main/data/twitter-2015train-A.txt\", delimiter='\\t', header=None, names=['id', 'label', 'tweet'])\n",
    "train_df_four = pd.read_csv(\"/content/drive/MyDrive/Sentiment_Detection/SemEval-2017-Task-4-A-B-C-using-BERT-main/SemEval-2017-Task-4-A-B-C-using-BERT-main/data/twitter-2014sarcasm-A.txt\", delimiter='\\t', header=None, names=['id', 'label', 'tweet'])\n",
    "test_data_df = pd.read_csv(\"/content/drive/MyDrive/Sentiment_Detection/SemEval-2017-Task-4-A-B-C-using-BERT-main/SemEval-2017-Task-4-A-B-C-using-BERT-main/data/twitter-2016test-A_final.txt\", delimiter='\\t', header=None, names=['label', 'tweet','id'])\n",
    "# test_data_df = pd.read_csv(\"/content/drive/MyDrive/Sentiment_Detection/Data/2017_English_final/GOLD/Subtask_A/SemEval2017-task4-test.subtask-A.english.txt\", delimiter='\\t', header=None, names=['id','label', 'tweet'])\n",
    "\n",
    "train_data_df = [train_df_one,train_df_two,train_df_three,train_df_four]\n",
    "train_data_df = pd.concat(train_data_df)\n",
    "\n",
    "train_tweet = train_data_df.tweet.values\n",
    "y_train = train_data_df.label.values\n",
    "\n",
    "test_tweet = test_data_df.tweet.values\n",
    "y_test = test_data_df.label.values\n",
    "\n",
    "# Change labels in Numeric values\n",
    "train_labels=[]\n",
    "test_labels=[]\n",
    "label_dict = {'negative':0, 'neutral':1, 'positive':2}\n",
    "\n",
    "for label in y_train:\n",
    "  train_labels.append(label_dict[label])\n",
    "\n",
    "for label in y_test:\n",
    "  test_labels.append(label_dict[label])\n",
    "\n",
    "print(\"We have {} training samples\".format(len(train_tweet)))\n",
    "print(\"We have {} test samples\".format(len(test_tweet)))\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# Use CountVectorization to convert text to a matrix of token counts\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(train_tweet)\n",
    "\n",
    "\n",
    "# Use TfidfTransformer to convert into matrix of TF-IDF features\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "\n",
    "# Train the Model\n",
    "model = MultinomialNB().fit(X_train_tfidf, train_labels)\n",
    "\n",
    "\n",
    "# Process the Test Data\n",
    "X_test_counts = count_vect.transform(test_tweet)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# Predict the Output\n",
    "predicted = model.predict(X_test_tfidf)\n",
    "\n",
    "\n",
    "# Find the Accuracy, precision, recall and F1 score\n",
    "test_acc =accuracy_score(test_labels, predicted)\n",
    "test_f1 = metrics.f1_score(test_labels, predicted, labels=[0, 1, 2], average='macro')\n",
    "test_precision = precision_score(test_labels, predicted,labels=[0, 1, 2], average='macro')\n",
    "test_recall = recall_score(test_labels, predicted,labels=[0, 1, 2], average='macro')\n",
    "\n",
    "print(f'test_acc: {test_acc:.4f}')\n",
    "print(f'f1 Score: {test_f1:.4f}')\n",
    "print(f'precision: {test_precision:.4f}')\n",
    "print(f'recall: {test_recall:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7M2nmikNH7GQ"
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "\n",
    "# Load DataSets\n",
    "train_df_one = pd.read_csv(\"/content/drive/MyDrive/Sentiment_Detection/SemEval-2017-Task-4-A-B-C-using-BERT-main/SemEval-2017-Task-4-A-B-C-using-BERT-main/data/twitter-2013train-A.txt\", delimiter='\\t', header=None, names=['id', 'label', 'tweet'])\n",
    "train_df_two = pd.read_csv(\"/content/drive/MyDrive/Sentiment_Detection/SemEval-2017-Task-4-A-B-C-using-BERT-main/SemEval-2017-Task-4-A-B-C-using-BERT-main/data/twitter-2016train-A.txt\", delimiter='\\t', header=None, names=['id', 'label', 'tweet'])\n",
    "train_df_three = pd.read_csv(\"/content/drive/MyDrive/Sentiment_Detection/SemEval-2017-Task-4-A-B-C-using-BERT-main/SemEval-2017-Task-4-A-B-C-using-BERT-main/data/twitter-2015train-A.txt\", delimiter='\\t', header=None, names=['id', 'label', 'tweet'])\n",
    "train_df_four = pd.read_csv(\"/content/drive/MyDrive/Sentiment_Detection/SemEval-2017-Task-4-A-B-C-using-BERT-main/SemEval-2017-Task-4-A-B-C-using-BERT-main/data/twitter-2014sarcasm-A.txt\", delimiter='\\t', header=None, names=['id', 'label', 'tweet'])\n",
    "test_data_df = pd.read_csv(\"/content/drive/MyDrive/Sentiment_Detection/SemEval-2017-Task-4-A-B-C-using-BERT-main/SemEval-2017-Task-4-A-B-C-using-BERT-main/data/twitter-2016test-A_final.txt\", delimiter='\\t', header=None, names=['label', 'tweet','id'])\n",
    "# test_data_df = pd.read_csv(\"/content/drive/MyDrive/Sentiment_Detection/Data/2017_English_final/GOLD/Subtask_A/SemEval2017-task4-test.subtask-A.english.txt\", delimiter='\\t', header=None, names=['id','label', 'tweet'])\n",
    "\n",
    "train_data_df = [train_df_one,train_df_two,train_df_three,train_df_four]\n",
    "train_data_df = pd.concat(train_data_df)\n",
    "\n",
    "train_tweet = train_data_df.tweet.values\n",
    "y_train = train_data_df.label.values\n",
    "\n",
    "test_tweet = test_data_df.tweet.values\n",
    "y_test = test_data_df.label.values\n",
    "\n",
    "# Change labels in Numeric values\n",
    "train_labels=[]\n",
    "test_labels=[]\n",
    "label_dict = {'negative':0, 'neutral':1, 'positive':2}\n",
    "\n",
    "for label in y_train:\n",
    "  train_labels.append(label_dict[label])\n",
    "\n",
    "for label in y_test:\n",
    "  test_labels.append(label_dict[label])\n",
    "\n",
    "print(\"We have {} training samples\".format(len(train_tweet)))\n",
    "print(\"We have {} test samples\".format(len(test_tweet)))\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# Use CountVectorization to convert text to a matrix of token counts\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(train_tweet)\n",
    "\n",
    "\n",
    "# Use TfidfTransformer to convert into matrix of TF-IDF features\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "\n",
    "# Train the Model\n",
    "model = MultinomialNB().fit(X_train_tfidf, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T4tax9mE1_SQ"
   },
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning for Multinomial Naive Bayes\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'alpha': [0.1, 0.5, 1.0, 2.0],  # Example values\n",
    "}\n",
    "\n",
    "# Create a MultinomialNB classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(nb_classifier, param_grid, cv=5)\n",
    "grid_search.fit(X_train_tfidf, train_labels)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Get the best model\n",
    "best_nb_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hOnI_VzK2NzP"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Process the Test Data\n",
    "X_test_counts = count_vect.transform(test_tweet)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# Predict the Output\n",
    "predicted = model.predict(X_test_tfidf)\n",
    "\n",
    "\n",
    "# Find the Accuracy, precision, recall and F1 score\n",
    "test_acc =accuracy_score(test_labels, predicted)\n",
    "test_f1 = metrics.f1_score(test_labels, predicted, labels=[0, 1, 2], average='macro')\n",
    "test_precision = precision_score(test_labels, predicted,labels=[0, 1, 2], average='macro')\n",
    "test_recall = recall_score(test_labels, predicted,labels=[0, 1, 2], average='macro')\n",
    "\n",
    "print(f'test_acc: {test_acc:.4f}')\n",
    "print(f'f1 Score: {test_f1:.4f}')\n",
    "print(f'precision: {test_precision:.4f}')\n",
    "print(f'recall: {test_recall:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DCrDZ3m32kC6"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "# Process the Test Data (assuming you've already performed Count Vectorization and TF-IDF transformation)\n",
    "X_test_counts = count_vect.transform(test_tweet)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "# Predict the Output using the best-tuned Naive Bayes model\n",
    "predicted = best_nb_model.predict(X_test_tfidf)\n",
    "\n",
    "# Find the Accuracy, precision, recall, and F1 score\n",
    "test_acc = accuracy_score(test_labels, predicted)\n",
    "test_f1 = metrics.f1_score(test_labels, predicted, labels=[0, 1, 2], average='macro')\n",
    "test_precision = precision_score(test_labels, predicted, labels=[0, 1, 2], average='macro')\n",
    "test_recall = recall_score(test_labels, predicted, labels=[0, 1, 2], average='macro')\n",
    "\n",
    "print(f'test_acc: {test_acc:.4f}')\n",
    "print(f'f1 Score: {test_f1:.4f}')\n",
    "print(f'precision: {test_precision:.4f}')\n",
    "print(f'recall: {test_recall:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aX8HL8wR4zuw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNUQB+2tiqXie7QDQgHAj6t",
   "mount_file_id": "15ZMcxJ8iT0jtabyRb97c1UlXQkCuGOG0",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
